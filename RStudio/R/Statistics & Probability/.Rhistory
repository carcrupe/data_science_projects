Length=NROW(tip),
tfrac=qt(p=0.90,df=Length-1),
Lower=tip.mean-tfrac*tip.sd/sqrt(Length),
Upper=tip.mean+tfrac*tip.sd/sqrt(Length))
ggplot(tipsByDay,aes(x=tip.mean,y=day))+geom_point()+
geom_errorbarh(aes(xmin=Lower,xmax=Upper),height=0.3)
ggplot(tipsByDay,aes(x=tip.mean,y=day))+geom_point()+
geom_errorbarh(aes(xmin=Lower,xmax=Upper),height=0.3)
plot(tips$total_bill,tips$tip)
lm_model<-lm(tip~total_bill,data=tips)
abline(lm_model,col="red",lwd=3)
cor(tips$total_bill,tips$tip)
shapiro.test(tips$tip)
lillie.test(tips$tip)
cor.test(tips$total_bill, tips$tip)
relation_daysize <-table(tips$day, tips$size)
relation_daysize
chisq.test(relation_daysize)
cor.test(tips$total_bill, tips$tip)
relation_daysize <-table(tips$day, tips$size)
relation_daysize
chisq.test(relation_daysize)
rm(list=ls())
#Carga los datos de inmuebles que se encuentran en la carpeta data_in
load(NULL)
#Visualiza previamente los datos
View(NULL)
#Carga los datos de inmuebles que se encuentran en la carpeta data_in
load("./data_in/inmuebles.Rdata")
#Visualiza previamente los datos
View(data_scrap)
#Podrias aproximar cual es la media poblacional de la localidad de Arroyomolinos (Madrid)?
df_temp<-data_scrap[which(data_scrap$level5 == "Arroypmolinos"),]
View(df_temp)
#Podrias aproximar cual es la media poblacional de la localidad de Arroyomolinos (Madrid)?
df_temp<-data_scrap[which(data_scrap$level5 == "Arroyomolinos"),]
#Podrias aproximar cual es la media poblacional de la localidad de Arroyomolinos (Madrid)?
df_temp<-data_scrap[which(data_scrap$level5 == "Arroyomolinos (Madrid"),]
#Podrias aproximar cual es la media poblacional de la localidad de Arroyomolinos (Madrid)?
df_temp<-data_scrap[which(data_scrap$level5 == "Arroyomolinos (Madrid)",]
#Podrias aproximar cual es la media poblacional de la localidad de Arroyomolinos (Madrid)?
df_temp<-data_scrap[which(data_scrap$level5 == "Arroyomolinos (Madrid)"),]
summary(df_temp)
summary(df_temp$price)
df_temp<-df_temp[which(df_temp$price>0),]
hist(df_temp)
hist(df_temp$price)
?hist
hist(df_temp$price )
lines(density(df_temp$price))
hist(df_temp$price, prob=T)
lines(density(df_temp$price))
hist(df_temp$price, prob=T)
lines(density(df_temp$price))
p<-df_temp$price
lillie.test(df_temp$price)
t.test(p,alternative = "two.sided",mu=295000)
mean(p)
data_scrap<-data_scrap[which(data_scrap$level5 in c("Fuenlabrada","Leganés","Getafe","Alcorcón"))]
data_scrap<-data_scrap[data_scrap$level5 in c("Fuenlabrada","Leganés","Getafe","Alcorcón")]
data_scrap<-data_scrap[data_scrap$level5 %in% c("Fuenlabrada","Leganés","Getafe","Alcorcón")]
data_scrap<-data_scrap[data_scrap$level5 %in% c("Fuenlabrada","Leganés","Getafe","Alcorcón"),]
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c(p,df_temp$rooms,df_temp$surface,df_temp$bathrooms)],function(x){round(mean(x),var(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c(p,df_temp$rooms,df_temp$surface,df_temp$bathrooms)],function(x){round(mean(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[c(p,df_temp$rooms,df_temp$surface,df_temp$bathrooms),],function(x){round(mean(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[c(p,df_temp$rooms,df_temp$surface,df_temp$bathrooms),],function(x){round(mean(x),var(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[c(p,df_temp$rooms,df_temp$surface,df_temp$bathrooms),],function(x){round(mean(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c("price","rooms","surface","bathrooms")],function(x){round(mean(x),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c("price","rooms","surface","bathrooms")],function(x){round(mean(x, rm.na=T),2)})
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c("price","rooms","surface","bathrooms")],function(x){round(mean(x, na.rm=T),2)})
#Realice el calculo por localidad
aggregate(data_scrap[,c("price","rooms","surface","bathrooms")], by = list(loc = data_scrap$level5), FUN = function(x){round(var(x, na.rm=T),2)})
#Realice el calculo por localidad
aggregate(data_scrap[,c("price","rooms","surface","bathrooms")], by = list(loc = data_scrap$level5), FUN = function(x){round(mean(x, na.rm=T),2)})
#Cual es la vivienda mas cara de cada localidad?
aggregate(data_scrap[,c("price","rooms","surface","bathrooms")], by = list(localidad=data_scrap$level5), FUN = function(x){round(max(p),2)})
#Cual es la vivienda mas cara de cada localidad?
aggregate(data_scrap[,c("price","rooms","surface","bathrooms")], by = list(localidad=data_scrap$level5), FUN = function(x){round(max(data_scrap$price),2)})
#Cual es la vivienda mas cara de cada localidad?
aggregate(data_scrap[,c("price")], by = list(localidad=data_scrap$level5), FUN = function(x){round(max(data_scrap$price),2)})
#Cual es la vivienda mas cara de cada localidad?
aggregate(data_scrap[,c("price")], by = list(localidad=data_scrap$level5), FUN = function(x){round(max(x),2)})
pal <- colorFactor(
palette = 'Dark2',
domain = data_scrap$level5
)
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=NULL,lat=NULL, radius = 5,  popup=NULL ,color = pal(NULL))
my_map
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=NULL,lat=NULL, radius = 5,  popup=NULL ,color = pal(NULL))
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=data_scrap$id_realEstates ,color = pal(NULL))
my_map
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=data_scrap$id_realEstates ,color = pal(NULL))
my_map
data_scrap<-data_scrap[data_scrap$price>0,]
lng=NULL,lat=NULL, radius = 5,  popup=NULL ,color = pal(NULL)
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=data_scrap$id_realEstates ,color = pal(NULL))
my_map
data_scrap<-data_scrap[data_scrap$price>0,]
data_scrap<-data_scrap[data_scrap$longitude>0,]
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=data_scrap$id_realEstates ,color = pal(NULL))
my_map
data_scrap<-data_scrap[which(data_scrap$latitude !=0 | data_scrap$longitude!=0),]
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=factor(data_scrap$id_realEstates) ,color = pal(data_scrap$level5))
my_map
data_scrap<-data_scrap[which(data_scrap$latitude !=0 | data_scrap$longitude!=0),]
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=factor(data_scrap$id_realEstates) ,color = pal(data_scrap$level5))
my_map
#Carga los datos de inmuebles que se encuentran en la carpeta data_in
load("./data_in/inmuebles.Rdata")
#Visualiza previamente los datos
View(data_scrap)
data_scrap<-data_scrap[which(data_scrap$latitude !=0 | data_scrap$longitude!=0),]
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=factor(data_scrap$id_realEstates) ,color = pal(data_scrap$level5))
my_map
#Carga los datos de inmuebles que se encuentran en la carpeta data_in
load("./data_in/inmuebles.Rdata")
data_scrap<-data_scrap[data_scrap$level5 %in% c("Fuenlabrada","Leganés","Getafe","Alcorcón"),]
# Calcula la media y varianza muestral de las variables precio, habitaciones, superficie y banos
sapply(data_scrap[,c("price","rooms","surface","bathrooms")],function(x){round(mean(x, na.rm=T),2)})
#Realice el calculo por localidad
aggregate(data_scrap[,c("price","rooms","surface","bathrooms")], by = list(loc = data_scrap$level5), FUN = function(x){round(mean(x, na.rm=T),2)})
#Cual es la vivienda mas cara de cada localidad?
aggregate(data_scrap[,c("price")], by = list(localidad=data_scrap$level5), FUN = function(x){round(max(x),2)})
pal <- colorFactor(
palette = 'Dark2',
domain = data_scrap$level5
)
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=data_scrap$id_realEstates ,color = pal(NULL))
my_map
data_scrap<-data_scrap[which(data_scrap$latitude !=0 | data_scrap$longitude!=0),]
my_map <- leaflet() %>%
addTiles() %>%  # use the default base map which is OpenStreetMap tiles
addCircleMarkers(lng=data_scrap$longitude,lat=data_scrap$latitude, radius = 5,  popup=factor(data_scrap$id_realEstates) ,color = pal(data_scrap$level5))
my_map
cor(data_scrap$surface,data_scrap$price)
is.null(data_scrap$surface)
is.null(data_scrap$price)
is.na(data_scrap$price)
data_scrap[is.na(data_scrap$surface)]
data_scrap[,is.na(data_scrap$surface)]
data_scrap<-data_scrap[which(!is.na(data_scrap$surface) & !is.na(data_scrap$price)),]
cor(data_scrap$surface,data_scrap$price)
plot(data_scrap$surface,data_scrap$price)
lm_model<-lm(price ~ surface,data=data_scrap)
abline(lm_model,col="red",lwd=3)
summary(lm_model)
cor.test(data_scrap$surface,data_scrap$price)
summary(lm_model)
cor.test(data_scrap$surface,data_scrap$price)
data_scrap<-data_scrap[which(data_scrap$price !=0),]
price_norm<-(data_scrap$price-mean(data_scrap$price))/sd(data_scrap$price)
lm_model<-lm(price_norm ~ data_scrap$surface)
plot(data_scrap$surface,price_norm)
abline(lm_model,col="red",lwd=3)
summary(lm_model)
p1<-plot_ly(data_scrap,y=~price,type = "box",name="price")
p2<-plot_ly(data_scrap,y=~rooms,type = "box",name="rooms")
p3<-plot_ly(data_scrap,y=~bathrooms,type = "box",name="bathrooms")
p4<-plot_ly(data_scrap,y=~surface,type = "box",name="surface")
p <- subplot(p1, p2,p3,p4,nrows=2)
p
na.omit(data_scrap)
data_scrap[rowSums(is.na(data_scrap)) < 2, ]
data_scrap$zipCode<-NULL
data_scrap$customZone<-NULL
nrow(na.omit(data_scrap))
data_scrap<-na.omit(data_scrap)
p1<-plot_ly(data_scrap,y=~price,type = "box",name="price")
p2<-plot_ly(data_scrap,y=~rooms,type = "box",name="rooms")
p3<-plot_ly(data_scrap,y=~bathrooms,type = "box",name="bathrooms")
p4<-plot_ly(data_scrap,y=~surface,type = "box",name="surface")
p <- subplot(p1, p2,p3,p4,nrows=2)
p
nrow(na.omit(data_scrap))
data_scrap<-na.omit(data_scrap)
plot_ly(data_scrap, y = ~price, x = ~level5, type = "box",color = ~level5)
plot_ly(data_scrap, y = ~surface, x = ~level5, type = "box",color = ~level5)
by(data = data_scrap,INDICES = data_scrap$level5,FUN = function(x){ boxplot.stats(x$price)$out})
remove_outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- x
y[x < (qnt[1] - H)] <- NA
y[x > (qnt[2] + H)] <- NA
y
}
library(dplyr)
data_scrap <- data_scrap %>%
group_by(level5) %>%
mutate(price = remove_outliers(price))
data_scrap <- data_scrap %>%
group_by(level5) %>%
mutate(surface = remove_outliers(surface))
data_scrap<-na.omit(as.data.frame(data_scrap))
data_scrap<-na.omit(as.data.frame(data_scrap))
par(mfrow = c(2,2))
qqnorm(data_scrap[data_scrap$level5 == "Fuenlabrada","price"], main = "Fuenlabrada")
qqline(data_scrap[data_scrap$level5 == "Fuenlabrada","price"])
qqnorm(data_scrap[data_scrap$level5 == "Leganés","price"], main = "Leganés")
qqline(data_scrap[data_scrap$level5 == "Leganés","price"])
qqnorm(data_scrap[data_scrap$level5 == "Getafe","price"], main = "Getafe")
qqline(data_scrap[data_scrap$level5 == "Getafe","price"])
qqnorm(data_scrap[data_scrap$level5 == "Alcorcón","price"], main = "Alcorcón")
qqline(data_scrap[data_scrap$level5 == "Alcorcón","price"])
#Realiza un t-test para determinar si la media de precios en Getafe es 250000
df_temp<-data_scrap[which(data_scrap$level5=="Getafe"),]
getafeTtest<-t.test(df_temp$price,alternative = "two.sided",mu=250000)
getafeTtest
randT<-rt(30000,df=NROW(df_temp)-1)
#graficamos
ggplot(data.frame(x=randT))+
geom_density(aes(x=x),fill="grey",color="grey") +
geom_vline(xintercept = getafeTtest$statistic) + #El estadístico T es la linea continua
geom_vline(xintercept = mean(randT) + c(-2,2)*sd(randT),linetype=2) #Media más o menos una desviación
df_temp<-data_scrap[which(data_scrap$level5 %in% c("Getafe","Alcorcón")),]
df_temp$pricem2<-df_temp$price/df_temp$surface
t.test(pricem2~level5,data=df_temp,var.equal=F)
data_scrap$pricem2<-data_scrap$price/data_scrap$surface
aggregate(pricem2~level5,data_scrap,function(x){mean(x,na.rm=T)})
anova <- aov(pricem2~level5,data=data_scrap)
summary(anova)
plot(anova)
rm(list=ls())
load("./data_in/inmuebles.Rdata")
data_scrap<-data_scrap[which(data_scrap$level5 %in% c("Valdemorillo","Galapagar")),]
aggregate(price~level5,data_scrap,function(x){mean(x,na.rm=T)})
ansari.test(price ~level5,data_scrap)
t.test(price~level5,data=data_scrap,var.equal=T)
ansari.test(price ~level5,data_scrap)
t.test(price~level5,data=data_scrap,var.equal=T)
t.test(price~level5,data=data_scrap,var.equal=T)
data_scrap$pricem2<-data_scrap$price/data_scrap$surface
aggregate(pricem2~level5,data_scrap,function(x){mean(x,na.rm=T)})
ansari.test(pricem2 ~level5,data_scrap)
t.test(pricem2~level5,data=data_scrap,var.equal=T)
ansari.test(pricem2 ~level5,data_scrap)
t.test(pricem2~level5,data=data_scrap,var.equal=T)
setwd("C:/Users/carlo/Desktop/Master Data Science/RStudio/R/Machine_learning/Supervised_learning")
library(dplyr)
advertising <- read.csv('advertising.csv', sep = ';', header = T, fileEncoding = 'utf-8')
glimpse(advertising)
library("ISLR")
auto <- read.csv('auto.csv', sep = ';', header = T, fileEncoding = 'utf-8')
glimpse(auto)
plot(auto$mpg,auto$horsepower)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
summary(auto_fit)
plot(auto$mpg,auto$horsepower)
abline(auto_fit, col = 'blue')
plot(auto$mpg,auto$horsepower)
abline(auto_fit, col = 'blue')
plot(auto$mpg,auto$horsepower, type = 'p')
abline(auto_fit, col = 'blue')
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
plot(auto$mpg,auto$horsepower, type = 'p')
abline(auto_fit, col = 'blue')
plot(auto$mpg,auto$horsepower, type = 'p')
summary(auto_fit)
glimpse(auto)
auto <- read.csv('auto.csv', sep = ',', header = T, fileEncoding = 'utf-8')
glimpse(auto)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
auto <- read.csv('auto.csv', sep = ';', header = T, fileEncoding = 'utf-8')
glimpse(auto)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
plot(auto$mpg,auto$horsepower, type = 'p')
?abline
auto_fit
lm_fit_sales_TV
lm_fit_sales_TV <- lm(Sales ~ TV, data = advertising)
lm_fit_sales_TV
auto <- read.csv('auto.csv', sep = ';', header = T, fileEncoding = 'utf-8')
glimpse(auto)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
plot(auto$mpg, auto_fit$residuals, type = 'p', col = 'red', xlab = 'mpg', ylab = 'residuals')
abline(auto_fit, col = 'blue')
plot.new
abline(auto_fit, col = 'blue')
plot.new(T)
plot(auto$mpg,auto$horsepower, type = 'p')
summary(auto_fit)
plot(auto$mpg,auto$horsepower, type = 'p')
abline(auto_fit)
summary(auto_fit)
auto <- read.csv('auto.csv', sep = ';')
glimpse(auto)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
plot(auto$mpg,auto$horsepower, type = 'p')
abline(auto_fit)
cor(auto$mpg,auto$horsepower)
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
summary(auto_fit)
plot(auto$mpg, auto_fit$residuals, type = 'p', col = 'red', xlab = 'mpg', ylab = 'residuals')
plot(auto$mpg,auto$horsepower, type = 'p')
abline(auto_fit)
?plot.new
plot.new()
plot(auto$mpg,auto$horsepower, type = 'p')
plot.new()
abline(auto_fit)
plot(auto$mpg,auto$horsepower, type = 'p')
plot.new()
summary(auto_fit[0],auto_fit[1])
abline(auto_fit[0],auto_fit[1])
plot(auto$mpg,auto$horsepower, type = 'p')
auto_fit <- lm(auto$mpg ~ auto$horsepower, data = auto)
plot(auto$mpg,auto$horsepower, type = 'p')
summary(auto_fit)
plot(auto$mpg, auto_fit$residuals, type = 'p', col = 'red', xlab = 'mpg', ylab = 'residuals')
plot(auto_fit, auto_fit$residuals, type = 'p', col = 'red', xlab = 'mpg', ylab = 'residuals')
plot(auto_fit, type = 'p', col = 'red', xlab = 'mpg', ylab = 'residuals')
plot(auto_fit)
lm_fit_sales_all <- lm(Sales ~ TV + Radio + Newspaper, data = advertising)
summary(lm_fit_sales_all)
lm_fit_sales_all <- lm(Sales ~ ., data = advertising)
lm_fit_sales_TV_Radio <- lm(Sales ~ . - Newspaper, data = advertising)
summary(lm_fit_sales_TV_Radio)
par(mfrow = c(1,2))
plot(advertising$Sales, lm_fit_sales_TV_Radio$fitted.values, type = 'p', col = 'red', xlab = 'Sales', ylab = 'Predicted Sales')
plot(advertising$Sales, lm_fit_sales_TV_Radio$residuals, type = 'p', col = 'red', xlab = 'Sales', ylab = 'Residuals')
plot(advertising$Sales, lm_fit_sales_TV_Radio$fitted.values, type = 'p', col = 'red', xlab = 'Sales', ylab = 'Predicted Sales')
plot(advertising$Sales, lm_fit_sales_TV_Radio$residuals, type = 'p', col = 'red', xlab = 'Sales', ylab = 'Residuals')
plot(advertising$Sales, lm_fit_sales_TV_Radio$residuals, type = 'p', col = 'red', xlab = 'Sales', ylab = 'Residuals')
library(dplyr)
advertising <- read.csv('advertising.csv', sep = ';', header = T, fileEncoding = 'utf-8')
glimpse(advertising)
advertising <- read.csv('advertising.csv', sep = ';', header = T, fileEncoding = 'utf-8')
setwd("C:/Users/carlo/Desktop/Master Data Science/RStudio/R/Machine_learning/Supervised_learning")
library(dplyr)
advertising <- read.csv('advertising.csv', sep = ';', header = T, fileEncoding = 'utf-8')
summary(advertising)
auto <- read.csv('auto.csv', sep = ';', header = T, fileEncoding = 'utf-8')
summary(auto)
lm_fit<- lm(mpg ~ horsepower, data = auto)
?lm
new_hp <- data.frame(horsepower = 98)
predicted_values <- predict(lm_fit, new_hp, interval = 'confidence', level = 0.99)
predicted_values
plot(horsepower, mpg, type = 'p', col = 'red')
abline(lm_fit, col = 'blue')
plot(auto$horsepower, auto$mpg, type = 'p', col = 'red')
abline(lm_fit, col = 'blue')
lm_fit_2<- lm(mpg ~ horsepower+ horsepower**2, data = auto)
lm_fit_3<- lm(mpg ~ horsepower+horsepower**2+horsepower**3, data = auto)
predicted_values <- predict(lm_fit_1)
lm_fit_1<- lm(mpg ~ horsepower, data = auto)
lm_fit_2<- lm(mpg ~ horsepower+ horsepower**2, data = auto)
lm_fit_3<- lm(mpg ~ horsepower+horsepower**2+horsepower**3, data = auto)
predicted_values <- predict(lm_fit_1)
install.packages('caret')
library('caret')
?caret
??caret
prep_training<- 0.8
n_iter<-10
lm_fit_1<- lm(mpg ~ horsepower, data = train_index_list)
lm_fit_2<- lm(mpg ~ horsepower+ horsepower**2, data = train_index_list)
lm_fit_3<- lm(mpg ~ horsepower+horsepower**2+horsepower**3, data = train_index_list)
predicted_values <- predict(lm_fit_1)
predicted_values
plot(auto$horsepower, auto$mpg, type = 'p', col = 'red')
abline(lm_fit_1, col = 'blue')
abline(lm_fit_2, col = 'black')
abline(lm_fit_3, col = 'green')
predicted_values_1 <- predict(lm_fit_1)
predicted_values_2 <- predict(lm_fit_2)
predicted_values_3 <- predict(lm_fit_3)
train_index_list
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
train_index_list
View(train_index_list)
View(train_index_list)
prep_training<- 0.6
n_iter<-10
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
train_index_list
lm_fit_1<- lm(mpg ~ horsepower, data = train_index_list)
lm_fit_2<- lm(mpg ~ horsepower+ horsepower**2, data = train_index_list)
lm_fit_3<- lm(mpg ~ horsepower+horsepower**2+horsepower**3, data = train_index_list)
predicted_values_1 <- predict(lm_fit_1)
predicted_values_2 <- predict(lm_fit_2)
prep_training<- 0.6
n_iter<-10
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
lm_fit_1<- lm(mpg ~ horsepower, data = train_index_list)
mpg <- mpg$train_index_list
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
mpg <- mpg$train_index_list
lm_fit_1<- lm(mpg ~ horsepower, data = train_index_list)
lm_fit_2<- lm(mpg ~ horsepower+ horsepower**2, data = train_index_list)
lm_fit_3<- lm(mpg ~ horsepower+horsepower**2+horsepower**3, data = train_index_list)
predicted_values_1 <- predict(lm_fit_1)
predicted_values_2 <- predict(lm_fit_2)
predicted_values_3 <- predict(lm_fit_3)
plot(auto$horsepower, auto$mpg, type = 'p', col = 'red')
abline(lm_fit_1, col = 'blue')
abline(lm_fit_2, col = 'black')
abline(lm_fit_3, col = 'green')
set.seed(42)
str(train_index_list)
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
str(train_index_list)
set.seed(42)
summary(auto)
prep_training<- 0.6
n_iter<-10
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
str(train_index_list)
lm_fit_1<- lm(mpg ~ horsepower, data = auto[train_index_list])
auto <- read.csv('auto.csv', sep = ';', header = T, fileEncoding = 'utf-8')
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
str(train_index_list)
lm_fit_1<- lm(mpg ~ horsepower, data = auto[train_index_list])
lm_fit_1<- lm(mpg ~ horsepower, data = auto[train_index_list,])
auto[train_index_list,]
train_index_list<-createDataPartition(1:nrow(auto),p=prep_training,times=n_iter)
str(train_index_list)
auto[train_index_list,]
a**2
a<-2
a**2
a<-3
a**2
lm_fit_1<- lm(mpg ~ horsepower, data = auto[which(train_index_list)])
which(train_index_list)
setwd("C:/Users/carlo/Desktop/Master Data Science/RStudio/R/Machine_learning/Supervised_learning")
knitr::opts_chunk$set(echo = TRUE)
data_path <- 'titanic.csv'
knitr::opts_chunk$set(echo = TRUE)
dim(titanic)
titanic <- read.csv(data_path, header = T, stringsAsFactors = F, encoding = 'utf-8')
dim(titanic)
str(titanic)
summary(titanic)
titanic$Age[is.na(titanic$Age)] <- median(titanic$Age, na.rm = T)
ggplot(data = titanic, aes(x = Sex, fill = factor(Survived))) + geom_bar(position = 'fill')
ggplot(data = titanic, aes(x = Pclass, fill = factor(Survived))) + geom_bar(position = 'fill')
ggplot(data = titanic, aes(x = Fare, fill = factor(Survived))) + geom_density() + facet_grid(Survived ~ .)
ggplot(data = titanic, aes(x = Age, fill = factor(Survived))) + geom_density() + facet_grid(Survived ~ .)
titanic$Survived <- as.factor(titanic$Survived)
```{r}
titanic$Sex <- as.factor(titanic$Sex)
titanic$Pclass <- as.ordered(titanic$Pclass) # OJO: http://stats.stackexchange.com/questions/105115/polynomial-contrasts-for-regression
library(caret)
library(caret)
set.seed(23)
split <- 0.7
trainIndex <- createDataPartition(titanic$Survived, p=split, list=FALSE)
head(trainIndex)
titanic_training <- titanic[trainIndex,]
titanic_test <- titanic[-trainIndex,]
first_model <- glm(Survived ~ ...,
data = ...,
family = binomial(link = 'logit'))
summary(first_model)
first_model <- glm(Survived ~ ...,
data = ...,
family = binomial(link = 'logit'))
first_model <- glm(Survived ~ c(Sex, PClass, Fare),
data = titanic_training,
family = binomial(link = 'logit'))
first_model <- glm(Survived ~ c(Sex, Pclass, Fare),
data = titanic_training,
family = binomial(link = 'logit'))
first_model <- glm(Survived ~ Sex, Pclass, Fare,
data = titanic_training,
family = binomial(link = 'logit'))
first_model <- glm(Survived ~ [Sex, Pclass, Fare],
first_model <- glm(Survived ~ [Sex, Pclass, Fare],
first_model <- glm(Survived ~ c(Sex, Pclass, Fare),
data = titanic_training,
family = binomial(link = 'logit'))
length(titanic_training$Survived)
length(titanic_training$Sex)
length(titanic_training$Pclass)
length(titanic_training$Fare)
first_model <- glm(Survived ~ (Sex+ Pclass+ Fare),
data = titanic_training,
family = binomial(link = 'logit'))
summary(first_model)
first_model <- glm(Survived ~ (Sex+ Pclass+ Fare + Age),
data = titanic_training,
family = binomial(link = 'logit'))
summary(first_model)
